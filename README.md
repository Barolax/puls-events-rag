# ğŸ­ Puls-Events RAG Chatbot

> Chatbot intelligent pour dÃ©couvrir les Ã©vÃ©nements culturels de Lille utilisant un systÃ¨me RAG (Retrieval Augmented Generation).

[![Python](https://img.shields.io/badge/Python-3.12-blue.svg)](https://www.python.org/)
[![LangChain](https://img.shields.io/badge/LangChain-0.3.0-green.svg)](https://langchain.com/)
[![Mistral AI](https://img.shields.io/badge/Mistral-AI-orange.svg)](https://mistral.ai/)

---

## ğŸ“‹ Description

Ce projet est un **Proof of Concept (POC)** d'un chatbot intelligent capable de :
- ğŸ” Rechercher des Ã©vÃ©nements culturels via Open Agenda
- ğŸ’¬ RÃ©pondre aux questions des utilisateurs de maniÃ¨re contextuelle
- ğŸ§  Maintenir une mÃ©moire conversationnelle
- ğŸ¯ Fournir des recommandations personnalisÃ©es

**Score d'Ã©valuation : 93.3%** (14/15 tests rÃ©ussis)

---

## ğŸ› ï¸ Technologies utilisÃ©es

| Technologie | RÃ´le |
|------------|------|
| **Mistral AI** | GÃ©nÃ©ration de rÃ©ponses et embeddings (mistral-large-latest, mistral-embed) |
| **Faiss** | Base de donnÃ©es vectorielle pour la recherche sÃ©mantique |
| **LangChain** | Orchestration du systÃ¨me RAG et gestion de la mÃ©moire |
| **Streamlit** | Interface web interactive |
| **Open Agenda API** | Source de donnÃ©es d'Ã©vÃ©nements culturels |
| **Pytest** | Tests unitaires et Ã©valuation |

---

## ğŸ“Š DonnÃ©es

- **Source** : Open Agenda - Ville de Lille
- **PÃ©riode couverte** : FÃ©vrier 2026 - FÃ©vrier 2027
- **Ã‰vÃ©nements rÃ©cupÃ©rÃ©s** : 457 Ã©vÃ©nements futurs
- **Documents vectorisÃ©s** : 611 documents (avec chunking intelligent)
- **Dimension des vecteurs** : 1024

### Chunking

Le systÃ¨me utilise un dÃ©coupage intelligent des textes :
- **Taille des chunks** : 500 caractÃ¨res
- **Chevauchement** : 50 caractÃ¨res
- **RÃ©sultat** : 138 Ã©vÃ©nements dÃ©coupÃ©s en 2-4 chunks

---

## ğŸš€ Installation

### PrÃ©requis

- Python 3.9+
- Compte Mistral AI ([CrÃ©er un compte](https://console.mistral.ai/))
- Compte Open Agenda ([CrÃ©er un compte](https://openagenda.com/))

### Ã‰tapes

1. **Cloner le repository**
```bash
git clone https://github.com/Barolax/puls-events-rag.git
cd puls-events-rag
```

2. **CrÃ©er l'environnement virtuel**
```bash
python -m venv venv
source venv/bin/activate  # Sur Mac/Linux
# ou
venv\Scripts\activate  # Sur Windows
```

3. **Installer les dÃ©pendances**
```bash
pip install -r requirements.txt
```

4. **Configurer les variables d'environnement**

CrÃ©er un fichier `.env` Ã  la racine :
```env
MISTRAL_API_KEY=votre_clÃ©_mistral_ici
OPENAGENDA_API_KEY=votre_clÃ©_openagenda_ici
```

5. **RÃ©cupÃ©rer et prÃ©parer les donnÃ©es**
```bash
python src/data_loader.py
python src/data_processor.py
```

6. **CrÃ©er la base vectorielle**
```bash
python -c "
import os, sys, json
sys.path.append('.')
from langchain_community.vectorstores import FAISS
from langchain_mistralai import MistralAIEmbeddings
from config import MISTRAL_API_KEY, MISTRAL_EMBED_MODEL, DATA_PROCESSED_PATH, VECTOR_STORE_PATH

with open(os.path.join(DATA_PROCESSED_PATH, 'documents_lille.json'), 'r') as f:
    documents = json.load(f)

texts = [doc['text'] for doc in documents]
metadatas = [doc['metadata'] for doc in documents]

embeddings = MistralAIEmbeddings(api_key=MISTRAL_API_KEY, model=MISTRAL_EMBED_MODEL)
vector_store = FAISS.from_texts(texts=texts, embedding=embeddings, metadatas=metadatas)
vector_store.save_local(VECTOR_STORE_PATH)
print('âœ… Base vectorielle crÃ©Ã©e !')
"
```

7. **Lancer l'application**
```bash
streamlit run app.py
```

L'interface s'ouvre automatiquement dans votre navigateur sur `http://localhost:8501`

---

## ğŸ§ª Tests

### Tests unitaires
```bash
pytest tests/test_data_validation.py -v
```

**RÃ©sultats** : 9/9 tests rÃ©ussis âœ…
- Validation des donnÃ©es (rÃ©gion, dates, formats)
- VÃ©rification de l'intÃ©gritÃ© des documents
- ContrÃ´le qualitÃ© des mÃ©tadonnÃ©es

### Ã‰valuation du chatbot
```bash
python tests/run_evaluation.py
```

**Score** : 93.3% (14/15 tests rÃ©ussis) ğŸ‰

CatÃ©gories testÃ©es :
- Recherche gÃ©nÃ©rale et spÃ©cifique
- Filtres (gratuit, public, lieu)
- Recherche temporelle
- MÃ©moire conversationnelle
- Gestion des questions hors contexte

---

## ğŸ“ Structure du projet
```
puls-events-rag/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py          # RÃ©cupÃ©ration donnÃ©es Open Agenda
â”‚   â”œâ”€â”€ data_processor.py       # Nettoyage et chunking
â”‚   â”œâ”€â”€ vector_store.py         # CrÃ©ation index Faiss
â”‚   â”œâ”€â”€ rag_chain.py            # ChaÃ®ne RAG LangChain
â”‚   â””â”€â”€ chatbot.py              # Logique du chatbot
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_data_validation.py # Tests unitaires (9/9)
â”‚   â”œâ”€â”€ test_dataset.json       # Jeu de donnÃ©es test (15 cas)
â”‚   â””â”€â”€ run_evaluation.py       # Ã‰valuation automatique
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # DonnÃ©es brutes (457 Ã©vÃ©nements)
â”‚   â””â”€â”€ processed/              # DonnÃ©es chunkÃ©es (611 documents)
â”œâ”€â”€ vector_store/
â”‚   â””â”€â”€ faiss_index/            # Base vectorielle Faiss
â”œâ”€â”€ app.py                      # Interface Streamlit
â”œâ”€â”€ config.py                   # Configuration centralisÃ©e
â”œâ”€â”€ requirements.txt            # DÃ©pendances
â””â”€â”€ README.md
```

---

## âš™ï¸ Configuration

Tous les paramÃ¨tres sont centralisÃ©s dans `config.py` :
```python
# ModÃ¨le Mistral
MISTRAL_MODEL = "mistral-large-latest"
MISTRAL_EMBED_MODEL = "mistral-embed"
TEMPERATURE = 0.4
MAX_TOKENS = 1000

# RAG
CHUNK_SIZE = 500
CHUNK_OVERLAP = 50
TOP_K_RESULTS = 5

# MÃ©moire conversationnelle
USE_MEMORY = True
MEMORY_WINDOW_SIZE = 5

# Open Agenda
OPENAGENDA_REGION = "Lille"
OPENAGENDA_MAX_EVENTS = 1000
```

---

## ğŸ’¡ Exemples d'utilisation
```
User: Quels concerts ont lieu Ã  Lille ?
Bot: Voici les concerts Ã  Lille : [liste avec dates, lieux, tarifs]

User: Y a-t-il des expositions gratuites ?
Bot: Oui ! Voici les expositions gratuites : [dÃ©tails]

User: C'est Ã  quelle heure ?
Bot: [Se souvient de l'exposition] L'exposition est ouverte de 14h Ã  18h.

User: Quel temps fait-il ?
Bot: Je suis spÃ©cialisÃ© dans les Ã©vÃ©nements culturels, pas la mÃ©tÃ©o ğŸ˜Š
```

---

## ğŸ¯ FonctionnalitÃ©s

âœ… Recherche sÃ©mantique avec Faiss (611 vecteurs)  
âœ… Chunking intelligent des textes longs  
âœ… Filtrage multi-critÃ¨res (type, date, tarif, public)  
âœ… MÃ©moire conversationnelle (5 derniers Ã©changes)  
âœ… RÃ©ponses contextuelles en franÃ§ais naturel  
âœ… Interface web intuitive (Streamlit)  
âœ… Tests unitaires et Ã©valuation automatique  
âœ… Gestion des questions hors contexte  

---

## ğŸ“ˆ Performances

| MÃ©trique | Valeur |
|----------|--------|
| **Score d'Ã©valuation** | 93.3% (14/15) |
| **Tests unitaires** | 9/9 rÃ©ussis |
| **Documents vectorisÃ©s** | 611 |

---

## ğŸ”§ Architecture RAG
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Question  â”‚
â”‚ utilisateur â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Vectorisation  â”‚
â”‚  (Mistral AI)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Recherche Faiss â”‚
â”‚  (Top 5 docs)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GÃ©nÃ©ration LLM â”‚
â”‚ + MÃ©moire (5)   â”‚
â”‚  (Mistral AI)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RÃ©ponse   â”‚
â”‚ contextualisÃ©e â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Livrables

- âœ… Code source versionnÃ© (GitHub)
- âœ… Tests unitaires (9/9 validÃ©s)
- âœ… Ã‰valuation chatbot (93.3%)
- âœ… Documentation technique (README)
- âœ… Interface Streamlit fonctionnelle
- âœ… Jeu de donnÃ©es test annotÃ©


